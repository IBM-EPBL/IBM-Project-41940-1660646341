{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Importing the required libraries\n",
    "import numpy\n",
    "import tensorflow\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers import Dense,Flatten\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "from keras.optimizers import Adam\n",
    "from keras.utils import np_utils\n",
    "Loading the data\n",
    "\n",
    "(X_train,y_train),(X_test,y_test)=mnist.load_data()\n",
    "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
    "11490434/11490434 [==============================] - 0s 0us/step\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "(60000, 28, 28)\n",
    "(10000, 28, 28)\n",
    "Analysing the data\n",
    "\n",
    "X_train[0]\n",
    "array([[  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
    "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
    "          0,   0],\n",
    "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
    "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
    "          0,   0],\n",
    "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
    "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
    "          0,   0],\n",
    "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
    "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
    "          0,   0],\n",
    "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
    "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
    "          0,   0],\n",
    "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   3,\n",
    "         18,  18,  18, 126, 136, 175,  26, 166, 255, 247, 127,   0,   0,\n",
    "          0,   0],\n",
    "       [  0,   0,   0,   0,   0,   0,   0,   0,  30,  36,  94, 154, 170,\n",
    "        253, 253, 253, 253, 253, 225, 172, 253, 242, 195,  64,   0,   0,\n",
    "          0,   0],\n",
    "       [  0,   0,   0,   0,   0,   0,   0,  49, 238, 253, 253, 253, 253,\n",
    "        253, 253, 253, 253, 251,  93,  82,  82,  56,  39,   0,   0,   0,\n",
    "          0,   0],\n",
    "       [  0,   0,   0,   0,   0,   0,   0,  18, 219, 253, 253, 253, 253,\n",
    "        253, 198, 182, 247, 241,   0,   0,   0,   0,   0,   0,   0,   0,\n",
    "          0,   0],\n",
    "       [  0,   0,   0,   0,   0,   0,   0,   0,  80, 156, 107, 253, 253,\n",
    "        205,  11,   0,  43, 154,   0,   0,   0,   0,   0,   0,   0,   0,\n",
    "          0,   0],\n",
    "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,  14,   1, 154, 253,\n",
    "         90,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
    "          0,   0],\n",
    "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 139, 253,\n",
    "        190,   2,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
    "          0,   0],\n",
    "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  11, 190,\n",
    "        253,  70,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
    "          0,   0],\n",
    "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  35,\n",
    "        241, 225, 160, 108,   1,   0,   0,   0,   0,   0,   0,   0,   0,\n",
    "          0,   0],\n",
    "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
    "         81, 240, 253, 253, 119,  25,   0,   0,   0,   0,   0,   0,   0,\n",
    "          0,   0],\n",
    "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
    "          0,  45, 186, 253, 253, 150,  27,   0,   0,   0,   0,   0,   0,\n",
    "          0,   0],\n",
    "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
    "          0,   0,  16,  93, 252, 253, 187,   0,   0,   0,   0,   0,   0,\n",
    "          0,   0],\n",
    "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
    "          0,   0,   0,   0, 249, 253, 249,  64,   0,   0,   0,   0,   0,\n",
    "          0,   0],\n",
    "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
    "          0,  46, 130, 183, 253, 253, 207,   2,   0,   0,   0,   0,   0,\n",
    "          0,   0],\n",
    "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  39,\n",
    "        148, 229, 253, 253, 253, 250, 182,   0,   0,   0,   0,   0,   0,\n",
    "          0,   0],\n",
    "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  24, 114, 221,\n",
    "        253, 253, 253, 253, 201,  78,   0,   0,   0,   0,   0,   0,   0,\n",
    "          0,   0],\n",
    "       [  0,   0,   0,   0,   0,   0,   0,   0,  23,  66, 213, 253, 253,\n",
    "        253, 253, 198,  81,   2,   0,   0,   0,   0,   0,   0,   0,   0,\n",
    "          0,   0],\n",
    "       [  0,   0,   0,   0,   0,   0,  18, 171, 219, 253, 253, 253, 253,\n",
    "        195,  80,   9,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
    "          0,   0],\n",
    "       [  0,   0,   0,   0,  55, 172, 226, 253, 253, 253, 253, 244, 133,\n",
    "         11,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
    "          0,   0],\n",
    "       [  0,   0,   0,   0, 136, 253, 253, 253, 212, 135, 132,  16,   0,\n",
    "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
    "          0,   0],\n",
    "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
    "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
    "          0,   0],\n",
    "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
    "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
    "          0,   0],\n",
    "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
    "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
    "          0,   0]], dtype=uint8)\n",
    "y_train[0]\n",
    "5\n",
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(X_train[0])\n",
    "\n",
    "Reshaping the data\n",
    "\n",
    "X_train=X_train.reshape(60000,28,28,1).astype('float32')\n",
    "X_test=X_test.reshape(10000,28,28,1).astype('float32')\n",
    "number_of_classes = 10\n",
    "Y_train = np_utils.to_categorical(y_train, number_of_classes)\n",
    "Y_test = np_utils.to_categorical(y_test, number_of_classes)\n",
    "Y_train[0]\n",
    "array([0., 0., 0., 0., 0., 1., 0., 0., 0., 0.], dtype=float32)\n",
    "Model creating\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(64, (3, 3), input_shape=(28, 28, 1), activation=\"relu\"))\n",
    "model.add(Conv2D(32, (3, 3), activation=\"relu\"))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(number_of_classes, activation=\"softmax\"))\n",
    "model.compile(loss='categorical_crossentropy', optimizer=\"Adam\", metrics=[\"accuracy\"])\n",
    "Train the model\n",
    "\n",
    "model.fit(X_train, Y_train, batch_size=32, epochs=5, validation_data=(X_test,Y_test))\n",
    "Epoch 1/5\n",
    "1875/1875 [==============================] - 173s 92ms/step - loss: 0.2504 - accuracy: 0.9488 - val_loss: 0.1019 - val_accuracy: 0.9681\n",
    "Epoch 2/5\n",
    "1875/1875 [==============================] - 167s 89ms/step - loss: 0.0731 - accuracy: 0.9778 - val_loss: 0.0710 - val_accuracy: 0.9767\n",
    "Epoch 3/5\n",
    "1875/1875 [==============================] - 170s 91ms/step - loss: 0.0494 - accuracy: 0.9840 - val_loss: 0.0922 - val_accuracy: 0.9752\n",
    "Epoch 4/5\n",
    "1875/1875 [==============================] - 168s 89ms/step - loss: 0.0408 - accuracy: 0.9872 - val_loss: 0.0952 - val_accuracy: 0.9756\n",
    "Epoch 5/5\n",
    "1875/1875 [==============================] - 169s 90ms/step - loss: 0.0304 - accuracy: 0.9904 - val_loss: 0.1016 - val_accuracy: 0.9745\n",
    "Test the model\n",
    "\n",
    "metrics = model.evaluate(X_test, Y_test, verbose=0)\n",
    "print(\"Metrics (Test Loss & Test Accuracy): \")\n",
    "print(metrics)\n",
    "Metrics (Test Loss & Test Accuracy): \n",
    "[0.10160219669342041, 0.9745000004768372]\n",
    "prediction = model.predict(X_test[:4])\n",
    "print(prediction)\n",
    "1/1 [==============================] - 0s 96ms/step\n",
    "[[3.1985040e-11 2.6928238e-12 1.1639130e-09 6.9380761e-08 2.0420460e-12\n",
    "  1.8735447e-11 5.4169054e-16 9.9999964e-01 1.5318657e-08 1.6423560e-07]\n",
    " [1.4883487e-10 1.7337460e-07 9.9999964e-01 3.5367054e-13 3.4504314e-13\n",
    "  1.5326859e-13 2.0963586e-07 1.7444811e-15 1.0131210e-09 2.1407159e-19]\n",
    " [5.0680144e-11 9.9996126e-01 6.1584583e-06 5.3597473e-14 1.0245189e-05\n",
    "  2.4711926e-07 4.3516887e-10 3.3853374e-07 2.1733187e-05 7.3300269e-11]\n",
    " [1.0000000e+00 2.2732191e-16 1.6053230e-09 3.4346147e-17 2.4410799e-12\n",
    "  1.0616660e-11 4.8161454e-11 1.3733837e-12 2.0989488e-10 6.1291361e-10]]\n",
    "print(numpy.argmax(prediction, axis=1))\n",
    "print(Y_test[:4])\n",
    "[7 2 1 0]\n",
    "[[0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
    " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
    " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
    " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
